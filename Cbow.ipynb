{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c4771-9f29-460f-b998-d24449ac2290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 98\n",
      "Training samples: 179\n"
     ]
    }
   ],
   "source": [
    "# cbow_keras.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# a. DATA PREPARATION\n",
    "# -----------------------------\n",
    "text = \"\"\"\n",
    "The speed of transmission is an important point of difference between the two viruses.\n",
    "Influenza has a shorter median incubation period (the time from infection to appearance of symptoms)\n",
    "and a shorter serial interval (the time between successive cases) than COVID-19 virus.\n",
    "The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus,\n",
    "the serial interval is 3 days. This means that influenza can spread faster than COVID-19.\n",
    "\n",
    "Further, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission\n",
    "–transmission of the virus before the appearance of symptoms – is a major driver of transmission\n",
    "for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus\n",
    "24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission.\n",
    "\n",
    "The reproductive number – the number of secondary infections generated from one infected individual –\n",
    "is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza.\n",
    "However, estimates for both COVID-19 and influenza viruses are very context and time-specific,\n",
    "making direct comparisons more difficult.\n",
    "\"\"\"\n",
    "\n",
    "# Clean and tokenize\n",
    "text = text.lower()\n",
    "text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "words = text.split()\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = sorted(set(words))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "# -----------------------------\n",
    "# b. GENERATE TRAINING DATA (CBOW)\n",
    "# -----------------------------\n",
    "window_size = 2\n",
    "contexts, targets = [], []\n",
    "\n",
    "for i in range(window_size, len(words) - window_size):\n",
    "    context = (\n",
    "        [word2idx[words[i - j]] for j in range(window_size, 0, -1)]\n",
    "        + [word2idx[words[i + j]] for j in range(1, window_size + 1)]\n",
    "    )\n",
    "    target = word2idx[words[i]]\n",
    "    contexts.append(context)\n",
    "    targets.append(target)\n",
    "\n",
    "contexts = np.array(contexts)\n",
    "targets = np.array(targets)\n",
    "print(\"Training samples:\", len(contexts))\n",
    "\n",
    "# -----------------------------\n",
    "# c. BUILD + TRAIN MODEL\n",
    "# -----------------------------\n",
    "embedding_dim = 50\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=window_size * 2),\n",
    "    layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)),  # average context embeddings\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.fit(contexts, targets, epochs=50000, verbose=0)\n",
    "print(\"✅ Training complete!\")\n",
    "\n",
    "# -----------------------------\n",
    "# d. OUTPUT – example predictions\n",
    "# -----------------------------\n",
    "def predict_next_word(context_words):\n",
    "    tokens = [word2idx[w] for w in context_words if w in word2idx]\n",
    "    if len(tokens) < 2 * window_size:\n",
    "        tokens = [0] * (2 * window_size - len(tokens)) + tokens\n",
    "    tokens = np.array(tokens[-2 * window_size:]).reshape(1, -1)\n",
    "    pred = model.predict(tokens, verbose=0)\n",
    "    return idx2word[np.argmax(pred)]\n",
    "\n",
    "\n",
    "\n",
    "# Print a few embeddings\n",
    "embeddings = model.layers[0].get_weights()[0]\n",
    "print(\"\\nSample word embeddings:\")\n",
    "for w in [\"virus\", \"transmission\", \"influenza\", \"covid19\" if \"covid19\" in word2idx else \"covid\"]:\n",
    "    print(w, embeddings[word2idx[w]][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715e3999-346b-4f3d-a43b-b6524d900255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['the', 'speed', 'of', 'transmission'] → Predicted word: 'of'\n",
      "Context: ['shorter', 'serial', 'for', 'virus'] → Predicted word: 'interval'\n",
      "Context: ['influenza', 'can', 'faster', 'than'] → Predicted word: 'spread'\n",
      "Context: ['number', 'of', 'secondary', 'infections'] → Predicted word: 'of'\n",
      "Context: ['the', 'time', 'from', 'infection'] → Predicted word: 'time'\n"
     ]
    }
   ],
   "source": [
    "test_contexts = [\n",
    "    [\"the\", \"speed\", \"of\", \"transmission\"],   # should predict “is” or “an”\n",
    "    [\"shorter\", \"serial\", \"for\", \"virus\"],    # should predict “interval”\n",
    "    [\"influenza\", \"can\", \"faster\", \"than\"],   # should predict “spread”\n",
    "    [\"number\", \"of\", \"secondary\", \"infections\"],  # should predict “generated”\n",
    "    [\"the\", \"time\", \"from\", \"infection\"],     # should predict “to”\n",
    "]\n",
    "\n",
    "for ctx in test_contexts:\n",
    "    pred = predict_next_word(ctx)\n",
    "    print(f\"Context: {ctx} → Predicted word: '{pred}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87117839-0f2d-4f0a-bf2b-0db19f573500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
